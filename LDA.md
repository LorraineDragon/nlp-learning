# LDA

Latent Dirichlet Allocation，隐含狄利克雷分布

### LDA 贝叶斯模型

LDA是基于贝叶斯模型的。

先验分布 + 数据（似然） = 后验分布

LDA模型求解，第一种是基于Gibbs采样算法求解，第二种是基于变分推断EM算法求解。

Gibbs采样可以很容易的并行化，因此也可以很方便的使用大数据平台来分布式的训练海量文档的LDA模型。

sklearn 包中，其算法实现主要基于原理篇里讲的变分推断EM算法，而没有使用基于Gibbs采样的MCMC算法实现。

具体到变分推断EM算法，scikit-learn还实现了另一种在线变分推断EM算法，它在变分推断EM算法的基础上，为了避免文档内容太多太大而超过内存大小，而提供了分步训练\(partial\_fit函数\)，即一次训练一小批样本文档，逐步更新模型，最终得到所有文档LDA模型的方法。



