# LDA

Latent Dirichlet Allocation，隐含狄利克雷分布

### LDA 贝叶斯模型

LDA是基于贝叶斯模型的。

先验分布 + 数据（似然） = 后验分布

LDA模型求解，第一种是基于Gibbs采样算法求解，第二种是基于变分推断EM算法求解。

Gibbs采样可以很容易的并行化，因此也可以很方便的使用大数据平台来分布式的训练海量文档的LDA模型。

sklearn 包中，其算法实现主要基于原理篇里讲的变分推断EM算法，而没有使用基于Gibbs采样的MCMC算法实现。

具体到变分推断EM算法，scikit-learn还实现了另一种在线变分推断EM算法，它在变分推断EM算法的基础上，为了避免文档内容太多太大而超过内存大小，而提供了分步训练\(partial\_fit函数\)，即一次训练一小批样本文档，逐步更新模型，最终得到所有文档LDA模型的方法。



 LDA是一个三层贝叶斯概率模型，包含词、主题和文档三层结构。文档到主题服从Dirichlet分布，主题到词服从多项式分布。     

 LDA是一种非监督机器学习技术，可以用来识别大规模文档集（document collection）或语料库（corpus）中潜藏的主题信息。它采用了词袋（bag of words）的方法，这种方法将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布。

