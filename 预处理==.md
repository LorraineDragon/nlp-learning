如果要做文本分类聚类，分词之后的关键步骤是：向量化 或 向量化特例 Hash Trick



背景知识

# 词袋模型

Bag of Words, BoW

#### 假设

不考虑文本中词与词之间的上下文关系，仅仅只考虑所有词的权重，而权重与词在文本中出现的频率有关。

#### 步骤

* ##### 分词 tokenizing
* ##### 统计修订词特征值 counting

        统计每个词在文本中出现的次数，可以得到该文本基于词的特征，将词与对应的词频放在一起，即向量化。

        向量化完毕后一般会使用TF-IDF进行特征的权重修正

* ##### 标准化 normalizing

#### 局限性

仅仅考虑词频，没有考虑上下文关系，因此会丢失一部分文本的语义。

但如果目的只是分类聚类，词袋模型表现的很好。



# 词集模型

Set of Words, SoW

与词袋模型唯一的不同是，它仅考虑词是否在文本中出现，而不考虑词频。

即，一个词在文本中出现一次和多次出现，特征处理是一样的。

多数时候还是采用词袋模型。













